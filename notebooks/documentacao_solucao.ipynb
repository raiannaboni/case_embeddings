{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8188cedf",
   "metadata": {},
   "source": [
    "# Documentação da Solução - Busca Semântica com FastText\n",
    "\n",
    "Este notebook documenta a solução desenvolvida para o case de Data Science focado em busca semântica de empresas usando FastText e técnicas de similaridade.\n",
    "\n",
    "## Sumário\n",
    "1. Introdução ao Problema\n",
    "2. Configuração do Ambiente\n",
    "3. Pré-processamento dos Dados\n",
    "4. Modelo FastText\n",
    "5. Sistema de Busca\n",
    "6. Avaliação e Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85140e0",
   "metadata": {},
   "source": [
    "## 1. Introdução ao Problema\n",
    "\n",
    "O desafio consiste em desenvolver um sistema de busca semântica que permita encontrar empresas a partir de texto livre digitado pelo usuário. O sistema deve:\n",
    "- Lidar com variações de escrita e erros de digitação\n",
    "- Considerar razão social e nome fantasia\n",
    "- Usar informações contextuais como UF\n",
    "- Retornar empresas ordenadas por similaridade\n",
    "\n",
    "As métricas de avaliação são:\n",
    "- Top-1: Percentual de acerto na primeira sugestão\n",
    "- Top-5: Percentual de acerto entre as 5 primeiras sugestões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8de9879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Nucleo Mundial de\n",
      "[nltk_data]     Ne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import FastText\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Download recursos NLTK\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee694f2",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Exploração dos Dados\n",
    "\n",
    "O dataset contém informações de empresas com os seguintes campos:\n",
    "- user_input: texto digitado pelo usuário\n",
    "- uf: estado da empresa\n",
    "- razaosocial: razão social oficial\n",
    "- nome_fantasia: nome fantasia da empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62512506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dataset: 255471\n",
      "\n",
      "Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>uf</th>\n",
       "      <th>razaosocial</th>\n",
       "      <th>nome_fantasia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAGAZINE L</td>\n",
       "      <td>SP</td>\n",
       "      <td>MAGAZINE LUIZA S/A</td>\n",
       "      <td>MAGAZINE LUIZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNEUS GP</td>\n",
       "      <td>PR</td>\n",
       "      <td>GP PNEUS LTDA</td>\n",
       "      <td>GP PNEUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SANTA CRUZ DISTRIBUIDORA</td>\n",
       "      <td>RS</td>\n",
       "      <td>DISTRIBUIDORA DE MEDICAMENTOS SANTA CRUZ LTDA</td>\n",
       "      <td>SANTA CRUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DROGALL</td>\n",
       "      <td>SP</td>\n",
       "      <td>DROGAL FARMACEUTICA LTDA</td>\n",
       "      <td>DROGAL JAGUARIUNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTAPAR BRASIL LTDA</td>\n",
       "      <td>ES</td>\n",
       "      <td>ALLPARK EMPREENDIMENTOS, PARTICIPACOES E SERVI...</td>\n",
       "      <td>ESTAPAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_input  uf  \\\n",
       "0                MAGAZINE L  SP   \n",
       "1                  PNEUS GP  PR   \n",
       "2  SANTA CRUZ DISTRIBUIDORA  RS   \n",
       "3                   DROGALL  SP   \n",
       "4       ESTAPAR BRASIL LTDA  ES   \n",
       "\n",
       "                                         razaosocial      nome_fantasia  \n",
       "0                                 MAGAZINE LUIZA S/A     MAGAZINE LUIZA  \n",
       "1                                      GP PNEUS LTDA           GP PNEUS  \n",
       "2      DISTRIBUIDORA DE MEDICAMENTOS SANTA CRUZ LTDA         SANTA CRUZ  \n",
       "3                           DROGAL FARMACEUTICA LTDA  DROGAL JAGUARIUNA  \n",
       "4  ALLPARK EMPREENDIMENTOS, PARTICIPACOES E SERVI...            ESTAPAR  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregamento dos dados\n",
    "df = pd.read_parquet('dados/train.parquet')\n",
    "df = df[['user_input', 'uf', 'razaosocial', 'nome_fantasia']].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamanho do dataset:\", len(df))\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b020f7",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento dos Dados\n",
    "\n",
    "### 3.1 Limpeza de Texto\n",
    "Foi implementada a seguinte função de limpeza que:\n",
    "- Remove acentos e caracteres especiais\n",
    "- Converte para minúsculas\n",
    "- Trata números como tokens especiais\n",
    "- Remove stopwords específicas do domínio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c1ec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: EMPRESA LTDA. & COMÉRCIO SA\n",
      "Limpo: empresa & comercio\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Pré-processamento otimizado para nomes de empresas\"\"\"\n",
    "    text = str(text).lower().strip()\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Remove caracteres especiais preservando números e alguns símbolos\n",
    "    text = re.sub(r'[^a-z0-9\\s&.-]', ' ', text)\n",
    "    \n",
    "    # Trata números como tokens especiais\n",
    "    text = re.sub(r'(\\d+)', r' \\1 ', text)\n",
    "    \n",
    "    # Remove stopwords específicas do domínio\n",
    "    stopwords = ['ltda.', 'me', 'epp', 'sa', 's/a', 'limitada', 'eireli']\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stopwords]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Exemplo\n",
    "texto = \"EMPRESA LTDA. & COMÉRCIO SA\"\n",
    "print(f\"Original: {texto}\")\n",
    "print(f\"Limpo: {clean_text(texto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c960bdb",
   "metadata": {},
   "source": [
    "### 3.2 Preparação dos Dados\n",
    "Foi criado um campo combinando razão social e nome fantasia, com peso maior para o nome fantasia por ser mais próximo do que os usuários digitam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38de18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_search_text(row):\n",
    "    \"\"\"Prepara texto para busca priorizando nome fantasia\"\"\"\n",
    "    razao = clean_text(str(row.razaosocial)) if pd.notna(row.razaosocial) else ''\n",
    "    fantasia = clean_text(str(row.nome_fantasia)) if pd.notna(row.nome_fantasia) else ''\n",
    "    \n",
    "    if razao and fantasia:        \n",
    "        return f\"{fantasia} {fantasia} {razao}\"  # Duplica nome fantasia para dar mais peso\n",
    "    \n",
    "    return fantasia or razao\n",
    "\n",
    "# Criação do campo target e split treino/teste\n",
    "df['target_empresa'] = (df.razaosocial.fillna('') + ' ' + df.nome_fantasia.fillna('')).apply(clean_text)\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplica prepare_search_text\n",
    "df_train['search_text'] = df_train.apply(prepare_search_text, axis=1)\n",
    "df_test['search_text'] = df_test.apply(prepare_search_text, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d8892",
   "metadata": {},
   "source": [
    "## 4. Modelo FastText\n",
    "\n",
    "### 4.1 Tokenização e Treinamento\n",
    "Foi implementada tokenização específica para empresas e treinado o modelo FastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "084664d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_business(text):\n",
    "    \"\"\"Tokenização específica para nomes de empresas\"\"\"\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    tokens = []\n",
    "    for word in text.split():\n",
    "        # Se tem número, mantém junto\n",
    "        if any(c.isdigit() for c in word):\n",
    "            tokens.append(word)\n",
    "        else:\n",
    "            # Mantém palavras pequenas (possíveis iniciais)\n",
    "            if len(word) <= 2:\n",
    "                tokens.append(word)\n",
    "            else:\n",
    "                tokens.extend(word_tokenize(word))\n",
    "    return tokens\n",
    "\n",
    "# Treina modelo FastText\n",
    "corpus_ft = [tokenize_business(text) for text in df_train.search_text]\n",
    "\n",
    "fasttext_model = FastText(\n",
    "    sentences=corpus_ft,\n",
    "    vector_size=300,     # Dimensão dos vetores\n",
    "    window=5,            # Janela de contexto\n",
    "    min_count=1,         # Inclui todas as palavras\n",
    "    sg=1,               # Skip-gram\n",
    "    negative=15,        # Negative sampling\n",
    "    epochs=50,          # Número de épocas\n",
    "    min_n=2,           # Tamanho mínimo de n-grams\n",
    "    max_n=6            # Tamanho máximo de n-grams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf6616",
   "metadata": {},
   "source": [
    "### 4.2 Embeddings com Pesos Adaptativos\n",
    "Foi implementada uma função que gera embeddings com pesos que se adaptam às características do texto:\n",
    "- Maior peso para primeiras palavras\n",
    "- Peso reduzido para tokens curtos\n",
    "- Normalização do vetor final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae91ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando embeddings...\n"
     ]
    }
   ],
   "source": [
    "def ft_embedding(text):\n",
    "    \"\"\"Gera embeddings com pesos adaptativos\"\"\"\n",
    "    tokens = tokenize_business(text)\n",
    "    vectors = []\n",
    "    weights = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in fasttext_model.wv:\n",
    "            vec = fasttext_model.wv[token]\n",
    "            weight = 1.0\n",
    "            \n",
    "            # Primeiras palavras são mais importantes\n",
    "            if i < 2:\n",
    "                weight *= 1.2\n",
    "            \n",
    "            # Tokens curtos têm peso menor\n",
    "            if len(token) <= 2:\n",
    "                weight *= 0.6\n",
    "                \n",
    "            vectors.append(vec)\n",
    "            weights.append(weight)\n",
    "    \n",
    "    if vectors:\n",
    "        weights = np.array(weights).reshape(-1, 1)\n",
    "        weighted_vectors = np.array(vectors) * weights\n",
    "        emb = np.sum(weighted_vectors, axis=0) / np.sum(weights)\n",
    "        return emb / np.linalg.norm(emb)\n",
    "    \n",
    "    return np.zeros(fasttext_model.vector_size)\n",
    "\n",
    "# Gera embeddings para treino e teste\n",
    "print(\"Gerando embeddings...\")\n",
    "df_train['ft_emb'] = df_train.search_text.apply(ft_embedding)\n",
    "df_test['ft_emb'] = df_test.search_text.apply(ft_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056cfc3",
   "metadata": {},
   "source": [
    "## 5. Sistema de Busca\n",
    "\n",
    "A busca é implementada usando uma função que:\n",
    "- Filtra por UF quando informada\n",
    "- Calcula similaridade de cosseno entre embeddings\n",
    "- Retorna as k empresas mais similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de88b531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemplo de busca:\n",
      "              razaosocial   nome_fantasia\n",
      "25799  ITAU UNIBANCO S.A.  BANCO ITAU S/A\n",
      "29998  ITAU UNIBANCO S.A.  BANCO ITAU S/A\n",
      "25014  ITAU UNIBANCO S.A.  BANCO ITAU S/A\n",
      "47325  ITAU UNIBANCO S.A.  BANCO ITAU S/A\n",
      "7707   ITAU UNIBANCO S.A.  BANCO ITAU S/A\n"
     ]
    }
   ],
   "source": [
    "def get_topk(user_input, uf=None, k=5, base_busca=None):\n",
    "    \"\"\"Busca as k empresas mais similares\"\"\"\n",
    "    texto = tokenize_business(user_input)\n",
    "    data = base_busca.copy()\n",
    "    \n",
    "    if uf:\n",
    "        data = data[data.uf == uf].reset_index(drop=True)\n",
    "    \n",
    "    emb = ft_embedding(texto)\n",
    "    similaridade = cosine_similarity([emb], list(data.ft_emb.values))[0]\n",
    "    \n",
    "    top_indices = similaridade.argsort()[::-1][:k]\n",
    "    return data.iloc[top_indices]\n",
    "\n",
    "# Exemplo de busca\n",
    "exemplo = get_topk('banco itau', uf='SP', base_busca=df_train)\n",
    "print(\"\\nExemplo de busca:\")\n",
    "print(exemplo[['razaosocial', 'nome_fantasia']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc338b",
   "metadata": {},
   "source": [
    "## 6. Avaliação e Resultados\n",
    "\n",
    "### 6.1 Função de Avaliação\n",
    "Foi implementada uma função que avalia as métricas Top-1 e Top-5 no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce2d375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_modelo(df_teste, base_busca, batch_size=32):\n",
    "    \"\"\"Avalia as métricas Top-1 e Top-5\"\"\"\n",
    "    total = len(df_teste)\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "    \n",
    "    # Pré-processamento dos alvos\n",
    "    alvos = df_teste.target_empresa.apply(clean_text).values\n",
    "    \n",
    "    with tqdm(total=total, desc='Avaliando modelo') as pbar:\n",
    "        for i in range(0, total, batch_size):\n",
    "            batch = df_teste.iloc[i:i+batch_size]\n",
    "            \n",
    "            for j, row in enumerate(batch.itertuples()):\n",
    "                entrada = row.user_input\n",
    "                uf = row.uf if hasattr(row, 'uf') else None\n",
    "                \n",
    "                resultados = get_topk(entrada, uf, k=5, base_busca=base_busca)\n",
    "                pred_empresas = resultados.target_empresa.apply(clean_text).values\n",
    "                \n",
    "                if alvos[i+j] == pred_empresas[0]:\n",
    "                    top1 += 1\n",
    "                if alvos[i+j] in pred_empresas:\n",
    "                    top5 += 1\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    print(f'\\nResultados:')\n",
    "    print(f'Top-1: {top1/total:.2%}')\n",
    "    print(f'Top-5: {top5/total:.2%}')\n",
    "    \n",
    "    return {'top1': top1/total, 'top5': top5/total}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4bfaa2",
   "metadata": {},
   "source": [
    "### 6.2 Resultados\n",
    "\n",
    "A avaliação do modelo no conjunto de teste mostra:\n",
    "- Top-1 Accuracy: Porcentagem de vezes que a primeira sugestão está correta\n",
    "- Top-5 Accuracy: Porcentagem de vezes que a resposta correta está entre as 5 primeiras sugestões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae11fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação final\n",
    "print(\"Avaliando modelo no conjunto de teste...\")\n",
    "resultados = avaliar_modelo(df_test, df_train)\n",
    "\n",
    "print(\"\\nExemplos de busca:\")\n",
    "queries = [\n",
    "    (\"banco itau\", \"SP\"),\n",
    "    (\"carrefour\", \"RJ\"),\n",
    "    (\"casas bahia\", None)\n",
    "]\n",
    "\n",
    "for query, uf in queries:\n",
    "    print(f\"\\nBusca: {query} (UF: {uf if uf else 'Todos'})\")\n",
    "    results = get_topk(query, uf=uf, k=3, base_busca=df_train)\n",
    "    print(results[['razaosocial', 'nome_fantasia']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a811b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso do sistema\n",
    "queries = [\n",
    "    (\"banco itau\", \"SP\"),\n",
    "    (\"carrefour\", \"RJ\"),\n",
    "    (\"casas bahia\", None)\n",
    "]\n",
    "\n",
    "print(\"Exemplos de busca:\")\n",
    "for query, uf in queries:\n",
    "    print(f\"\\nBusca: {query} (UF: {uf if uf else 'Todos'})\")\n",
    "    resultados = get_topk(query, uf=uf, k=3, base_busca=df_train)\n",
    "    print(resultados[['razaosocial', 'nome_fantasia']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
