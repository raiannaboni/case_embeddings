{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c46cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import FastText\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos dados\n",
    "df = pd.read_parquet('dados/train.parquet')\n",
    "df = df[['user_input', 'uf', 'razaosocial', 'nome_fantasia']].reset_index(drop=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Pré-processamento melhorado\"\"\"\n",
    "    text = str(text).lower().strip()\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Preserva números e caracteres especiais importantes\n",
    "    text = re.sub(r'[^a-z0-9\\s&.-]', ' ', text)\n",
    "    \n",
    "    # Trata números como tokens especiais\n",
    "    text = re.sub(r'(\\d+)', r' \\1 ', text)\n",
    "    \n",
    "    # Remove stopwords específicas do domínio\n",
    "    stopwords = ['ltda', 'me', 'epp', 'sa', 's/a', 'limitada', 'eireli', 'comercio', 'servicos']\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stopwords]\n",
    "    \n",
    "    # Normaliza espaços\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do campo de texto e do target\n",
    "df['target_empresa'] = (df.razaosocial.fillna('') + ' ' + df.nome_fantasia.fillna('')).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduzido = df[:10000]\n",
    "\n",
    "# Separação treino/teste\n",
    "df_train, df_test = train_test_split(df_reduzido, \n",
    "                                     test_size=0.2, \n",
    "                                     random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43927d",
   "metadata": {},
   "source": [
    "# FastText training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb10670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preparar o texto para busca, priorizando nome fantasia\n",
    "def prepare_search_text(row):\n",
    "    razao = clean_text(str(row.razaosocial)) if pd.notna(row.razaosocial) else ''\n",
    "    fantasia = clean_text(str(row.nome_fantasia)) if pd.notna(row.nome_fantasia) else ''\n",
    "    \n",
    "    # Se tiver ambos, combina dando mais peso ao nome fantasia\n",
    "    if razao and fantasia:\n",
    "        # Repete o nome fantasia para dar mais peso\n",
    "        return f\"{fantasia} {fantasia} {razao}\"\n",
    "    # Se tiver só um deles, usa o que tiver\n",
    "    return fantasia or razao\n",
    "\n",
    "# Aplica o prepare_search_text em todos os DataFrames\n",
    "df_train['search_text'] = df_train.apply(prepare_search_text, axis=1)\n",
    "df_test['search_text'] = df_test.apply(prepare_search_text, axis=1)\n",
    "\n",
    "# Tokenização específica para nomes de empresas\n",
    "def tokenize_business(text):\n",
    "    \"\"\"Tokenização que preserva partes importantes do nome\"\"\"\n",
    "    text = str(text).lower().strip()\n",
    "    # Remove acentos\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Preserva números e caracteres especiais importantes\n",
    "    text = re.sub(r'[^a-z0-9\\s&.-]', ' ', text)  # Corrigido o regex\n",
    "    \n",
    "    # Trata números como tokens especiais\n",
    "    text = re.sub(r'(\\d+)', r' \\1 ', text)\n",
    "    \n",
    "    # Normaliza espaços\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    tokens = []\n",
    "    for word in text.split():\n",
    "        # Se tem número, mantém junto\n",
    "        if any(c.isdigit() for c in word):\n",
    "            tokens.append(word)\n",
    "        else:\n",
    "            # Tokeniza mas mantém palavras pequenas (possíveis iniciais)\n",
    "            if len(word) <= 2:\n",
    "                tokens.append(word)\n",
    "            else:\n",
    "                tokens.extend(word_tokenize(word))\n",
    "    return tokens\n",
    "\n",
    "# FastText com parâmetros otimizados para nomes de empresas\n",
    "corpus_ft = [tokenize_business(text) for text in df_train.search_text]\n",
    "\n",
    "fasttext_model = FastText(\n",
    "    sentences=corpus_ft,\n",
    "    vector_size=500,     # Aumentar dimensionalidade\n",
    "    window=5,            # Aumentar janela para capturar mais contexto\n",
    "    min_count=1,        # Manter palavras raras\n",
    "    sg=1,               # Skip-gram\n",
    "    hs=1,               # Hierarchical softmax\n",
    "    negative=15,        # Aumentar negative sampling\n",
    "    epochs=50,         # Aumentar épocas\n",
    "    min_n=1,           # Subpalavras menores\n",
    "    max_n=8,           # Subpalavras maiores\n",
    "    workers=4          # Paralelização\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def improved_ft_embedding(text):\n",
    "    \"\"\"Função melhorada para gerar embeddings com pesos adaptativos\"\"\"\n",
    "    tokens = tokenize_business(text)\n",
    "    vectors = []\n",
    "    weights = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in fasttext_model.wv:\n",
    "            vec = fasttext_model.wv[token]\n",
    "            # Pesos adaptativos baseados nas características do token\n",
    "            weight = 1.0\n",
    "            \n",
    "            # Primeiras palavras são mais importantes\n",
    "            if i < 2:\n",
    "                weight *= 1.6\n",
    "            \n",
    "            # # Tokens com números são importantes (filiais, números de loja)\n",
    "            # if any(c.isdigit() for c in token):\n",
    "            #     weight *= 1.3\n",
    "            \n",
    "            # Tokens curtos (possíveis iniciais) têm peso menor\n",
    "            if len(token) <= 2:\n",
    "                weight *= 0.4\n",
    "                \n",
    "            vectors.append(vec)\n",
    "            weights.append(weight)\n",
    "    \n",
    "    if vectors:\n",
    "        weights = np.array(weights).reshape(-1, 1)\n",
    "        weighted_vectors = np.array(vectors) * weights\n",
    "        # Normaliza o embedding final\n",
    "        emb = np.sum(weighted_vectors, axis=0) / np.sum(weights)\n",
    "        return emb / np.linalg.norm(emb)\n",
    "    \n",
    "    return np.zeros(fasttext_model.vector_size)\n",
    "\n",
    "# Aplica os novos embeddings\n",
    "print(\"Gerando embeddings FastText...\")\n",
    "df_train['ft_emb'] = df_train.search_text.apply(improved_ft_embedding)\n",
    "df_test['ft_emb'] = df_test.search_text.apply(improved_ft_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de0925",
   "metadata": {},
   "source": [
    "## Avaliar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f1f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk(model_name, user_input, uf=None, k=5, base_busca=None):\n",
    "    texto = clean_text(user_input)\n",
    "    data = base_busca.copy()\n",
    "    \n",
    "    if uf:\n",
    "        data = data[data.uf == uf].reset_index(drop=True)\n",
    "    \n",
    "    if model_name == 'fasttext':\n",
    "        # Usa a função ft_embedding para gerar o embedding do FastText\n",
    "        emb = improved_ft_embedding(texto)\n",
    "        sims = cosine_similarity([emb], list(data.ft_emb.values))[0]\n",
    "    elif model_name == 'tfidf':\n",
    "        vec = tfidf.transform([texto])\n",
    "        # Garantimos que estamos usando os índices corretos do DataFrame original\n",
    "        indices_originais = data.index.values\n",
    "        sims = cosine_similarity(vec, tfidf_matrix[indices_originais])[0]\n",
    "    elif model_name == 'bert':\n",
    "        emb = bert_model.encode([texto])[0]\n",
    "        sims = cosine_similarity([emb], list(data.bert_emb.values))[0]\n",
    "\n",
    "    top_indices = sims.argsort()[::-1][:k]\n",
    "    return data.iloc[top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_modelo(model_name, df_teste, base_busca, batch_size=32):\n",
    "    total = len(df_teste)\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "    \n",
    "    # Pré-processamento dos alvos\n",
    "    alvos = df_teste.target_empresa.apply(clean_text).values\n",
    "    \n",
    "    # Processamento em lotes com barra de progresso\n",
    "    with tqdm(total=total, desc=f'Avaliando {model_name}') as pbar:\n",
    "        for i in range(0, total, batch_size):\n",
    "            batch = df_teste.iloc[i:i+batch_size]\n",
    "            \n",
    "            # Processa cada entrada do lote\n",
    "            for j, row in enumerate(batch.itertuples()):\n",
    "                entrada = row.user_input\n",
    "                uf = row.uf if hasattr(row, 'uf') else None\n",
    "                \n",
    "                # Obtém os top-k resultados\n",
    "                resultados = get_topk(model_name, entrada, uf, k=5, base_busca=base_busca)\n",
    "                pred_empresas = resultados.target_empresa.apply(clean_text).values\n",
    "                \n",
    "                # Atualiza métricas usando comparação vetorizada\n",
    "                if alvos[i+j] == pred_empresas[0]:\n",
    "                    top1 += 1\n",
    "                if alvos[i+j] in pred_empresas:\n",
    "                    top5 += 1\n",
    "                \n",
    "                # Atualiza a barra de progresso\n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Calcula e mostra as métricas\n",
    "    print(f'\\nModelo: {model_name}')\n",
    "    print(f'Top-1: {top1/total:.2%} | Top-5: {top5/total:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo('fasttext', df_test, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topk('fasttext', 'rener', uf='SP', base_busca=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d275f",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86070a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_similarity(query, target, query_vec, target_vec, uf_match=False):\n",
    "    \"\"\"Similaridade híbrida com múltiplos fatores\"\"\"\n",
    "    # Similaridade FastText\n",
    "    ft_sim = cosine_similarity([query_vec], [target_vec])[0][0]\n",
    "    \n",
    "    # Similaridade de caracteres\n",
    "    char_sim = fuzz.ratio(query, target) / 100.0\n",
    "    \n",
    "    # Similaridade de prefixo\n",
    "    prefix_sim = 1.0 if target.startswith(query) else 0.0\n",
    "    \n",
    "    # Similaridade por tokens comuns\n",
    "    query_tokens = set(query.split())\n",
    "    target_tokens = set(target.split()) \n",
    "    token_sim = len(query_tokens & target_tokens) / len(query_tokens | target_tokens)\n",
    "    \n",
    "    # Pesos diferentes baseado no tamanho da query\n",
    "    if len(query) < 5:\n",
    "        final_sim = 0.4*ft_sim + 0.3*char_sim + 0.2*prefix_sim + 0.1*token_sim\n",
    "    else:\n",
    "        final_sim = 0.5*ft_sim + 0.2*char_sim + 0.1*prefix_sim + 0.2*token_sim\n",
    "    \n",
    "    # Boost para match de UF\n",
    "    if uf_match:\n",
    "        final_sim *= 1.2\n",
    "        \n",
    "    return final_sim\n",
    "\n",
    "def avaliar_hybrid_similarity(df_teste, base_busca, batch_size=32):\n",
    "    \"\"\"Avalia as métricas Top-1 e Top-5 usando hybrid_similarity\"\"\"\n",
    "    print(\"\\nAvaliando modelo Híbrido...\")\n",
    "    total = len(df_teste)\n",
    "    top1 = 0 \n",
    "    top5 = 0\n",
    "\n",
    "    # Pré-processamento dos alvos\n",
    "    alvos = df_teste.target_empresa.apply(clean_text).values\n",
    "\n",
    "    with tqdm(total=total, desc='Avaliando Híbrido') as pbar:\n",
    "        for i in range(0, total, batch_size):\n",
    "            batch = df_teste.iloc[i:i+batch_size]\n",
    "            \n",
    "            for j, row in enumerate(batch.itertuples()):\n",
    "                entrada = row.user_input\n",
    "                uf = row.uf if hasattr(row, 'uf') else None\n",
    "                \n",
    "                texto = clean_text(entrada)\n",
    "                query_vec = improved_ft_embedding(texto)\n",
    "                \n",
    "                # Calcula similaridades\n",
    "                similarities = []\n",
    "                for idx, target_row in base_busca.iterrows():\n",
    "                    target = clean_text(target_row.target_empresa)\n",
    "                    target_vec = target_row.ft_emb\n",
    "                    \n",
    "                    sim = hybrid_similarity(\n",
    "                        texto, \n",
    "                        target,\n",
    "                        query_vec, \n",
    "                        target_vec,\n",
    "                        uf_match=(uf == target_row.uf if uf else False)\n",
    "                    )\n",
    "                    similarities.append(sim)\n",
    "\n",
    "                # Obtém top-k mais similares\n",
    "                top_indices = np.array(similarities).argsort()[::-1][:5]\n",
    "                pred_empresas = base_busca.iloc[top_indices].target_empresa.apply(clean_text).values\n",
    "                \n",
    "                # Atualiza métricas\n",
    "                if alvos[i+j] == pred_empresas[0]:\n",
    "                    top1 += 1\n",
    "                if alvos[i+j] in pred_empresas:\n",
    "                    top5 += 1\n",
    "                    \n",
    "                pbar.update(1)\n",
    "    \n",
    "    print(f'\\nModelo: Hybrid Similarity')\n",
    "    print(f'Top-1: {top1/total:.2%} | Top-5: {top5/total:.2%}')\n",
    "    \n",
    "    return {'top1': top1/total, 'top5': top5/total}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = avaliar_hybrid_similarity(df_test, df_train)\n",
    "print(f\"Top-1 Accuracy: {resultados['top1']:.4f}\")\n",
    "print(f\"Top-5 Accuracy: {resultados['top5']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c627aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f9a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095de611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1056d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68447ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd3462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
